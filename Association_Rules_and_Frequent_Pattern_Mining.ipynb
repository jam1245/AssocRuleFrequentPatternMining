{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 2 - Lab using R\n",
    "\n",
    "\n",
    "In this notebook the R package [**`arules`**](https://cran.r-project.org/web/packages/arules/vignettes/arules.pdf) is used that has functions for creating and manipulating data for ining association rules and also analyze the resulting itemsets and rules. It also includes interfaces for some of the popular mining algorithms **`Apriori`** and **`Eclat`** by Christian Borgelt. \n",
    "\n",
    "**_Apriori: _ ** is a level-wise, breadth-first algorithm which counts transactions. Go through the slides to understand how apriori works. \n",
    "\n",
    "**_Eclat: _** employs equivalence classes, depth-first search and set intersection instead of counting. These algorithms can mine frequent itemsets, maximal frequent itemsets, closed frequent itemsets and association rules. Different measures of interestingness are used to describe analyze and present association rules discovered in data. Some of these measures are discussed as following. \n",
    "\n",
    "\n",
    "** Association Rules:** Let I = {i1, i2, . . . , in} be a set of n binary attributes called items. Let D = {t1, t2, . . . , tm}\n",
    "be a set of transactions called the database. Each transaction in D has a unique transaction ID and contains a subset of the items in I. A rule is defined as an implication of the form **X ⇒ Y** where **_X_, _Y_ ⊆ _I_** and **_X_ ∩ _Y_ = ∅**. The sets of items (for short itemsets) X and Y are called antecedent (LHS) and consequent (RHS) of the rule.\n",
    "\n",
    "\n",
    "As explained in slides, consider the example from the supermarket domain. The set of items is I = {milk, bread, butter, beer} and a small database containing the items is shown below. \n",
    "\n",
    "<img src='../images/market_data.PNG'>\n",
    "\n",
    "An example rule for the supermarket could be {milk, bread} ⇒ {butter} meaning that if milk and bread is bought, customers also buy butter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representing collections of itemsets\n",
    "\n",
    "\n",
    "Both transaction databases and sets of associations have in common that they contain sets of items (itemsets) together with additional information. For example, a transaction in the database contains a transaction ID and an itemset. A rule in a set of mined association rules contains two itemsets, one for the LHS and one for the RHS, and additional quality information, e.g., values for various interest measures.\n",
    "\n",
    "Collections of itemsets used for transaction databases and sets of associations can be represented as binary incidence matrices with columns corresponding to the items and rows corresponding to the itemsets. The matrix entries represent the presence (1) or absence (0) of an item in a particular itemset. Shown below on the left, an example of a binary incidence matrix containing itemsets for above supermarket data example and vertical layout for the same is shown on right. \n",
    "\n",
    "<img src=\"../images/data_representation.PNG\">\n",
    "\n",
    "\n",
    "Since a typical frequent itemset or a typical transaction (e.g., a supermarket transaction)\n",
    "only contains a small number of items compared to the total number of available items, the\n",
    "binary incidence matrix will in general be very sparse with many items and a very large\n",
    "number of rows. A natural representation for such data is a sparse matrix format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Associations: itemsets and sets of rules\n",
    "\n",
    "\n",
    "Mining transaction data using arules package results in finding associations. Conceptually, associations are sets of objects describing the relationship between some items which have assigned values for different measures of quality. Such measures can be measures of significance (e.g., support), or measures of interestingness (e.g., confidence, lift), or other measures (e.g., revenue covered by the association).\n",
    "\n",
    "\n",
    "### Sampling from transactions\n",
    "\n",
    "Taking samples from large databases for mining is a powerful technique which is especially useful if the original database does not fit into main memory, but the sample does. However, even if the database fits into main memory, sampling can provide an enormous speed-up for mining at the cost of only little degradation of accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing and mining a questionnaire data set\n",
    "\n",
    "Analyze and manipulate the dataset before any associations are mined. Its an important step as it helps find problems in the data set which could make the mined associations useless or at least inferior to associations mined on a properly prepared data set. \n",
    "\n",
    "The notebook uses the Adult dataset from the UCI machine learning repository provided by package **[arules](https://cran.r-project.org/web/packages/arules/vignettes/arules.pdf)**. This data set originates from the U.S. census bureau database and contains 48842 instances with 14 attributes like age, work class, education, etc. In the original applications of the data, the attributes were used to predict the income level of individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# install.packages(\"arules\",repo=\"http://cran.mtu.edu/\")\n",
    "library(\"arules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data(\"AdultUCI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dim(AdultUCI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at first two rows in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AdultUCI[1:2,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is a combination of categorical and numeric attributes. It needs some data cleaning before it can be converted into transaction data for any association rule mining. First, remove the attributes **fnlwgt** and **education-num**. **fnlwgt** is a weight calculated by the creator of the data set. **education-num** is just a numeric representation of the attribute education which is also part of the data set.\n",
    "\n",
    "Assigning a column to NULL will delete the column from dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AdultUCI[[\"fnlwgt\"]] <- NULL\n",
    "AdultUCI[[\"education-num\"]] <- NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, map the four numeric attributes (age, hours-per-week, capital-gain and capital-loss) to ordinal attributes by building suitable categories. Divide the attributes age and hours-per-week into suitable categories using knowledge about typical age groups and working hours. For the two capital related attributes, create a category called None for cases which have no gains/losses. Further divide the group with gains/losses at their median into two categories Low and High."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Ordered factors are different from factors:_ ** Ordered values are similar to factor type data and is like an extension of factors. To create an ordered factor in R, you have two options:\n",
    "- Use the factor() function with the argument ordered=TRUE.\n",
    "- Use the ordered() function.\n",
    "\n",
    "Use the factor() function for nominal data and the ordered() function for ordinal data. R then will treat the data appriopriately. Factor and ordered are used the same way, with the same arguments. The former creates factors and the later creates ordered factors. [Click this link](http://www.dummies.com/programming/r/how-to-work-with-ordered-factors-in-r/) for more info.\n",
    "\n",
    "----\n",
    "**_cut():_** From R library, cut divides the range of x into intervals and codes the values in x according to which interval they fall. The leftmost interval corresponds to level one, the next leftmost to level two and so on.\n",
    "\n",
    "So in below lines of code, we are splitting the column data into intervals as specified in the vector c() and code them into values according to list of labels. The order of labels is important labels = c(\"Young\", \"Middle-aged\", \"Senior\", \"Old\") is different from labels = c(\"old\",\"Senior\", \"Middle-aged\",\"Young\"). You have to tell R the right order of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AdultUCI[[ \"age\"]] <- ordered(cut(AdultUCI[[ \"age\"]], c(15,25,45,65,100)), labels = c(\"Young\", \"Middle-aged\", \"Senior\", \"Old\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AdultUCI[[ \"hours-per-week\"]] <- ordered(cut(AdultUCI[[ \"hours-per-week\"]], c(0,25,40,60,168)), labels = c(\"Part-time\", \"Full-time\", \"Over-time\", \"Workaholic\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AdultUCI[[ \"capital-gain\"]] <- ordered(cut(AdultUCI[[ \"capital-gain\"]], c(-Inf,0,median(AdultUCI[[ \"capital-gain\"]][AdultUCI[[ \"capital-gain\"]]>0]),Inf)),labels = c(\"None\", \"Low\", \"High\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AdultUCI[[ \"capital-loss\"]] <- ordered(cut(AdultUCI[[ \"capital-loss\"]],c(-Inf,0, median(AdultUCI[[ \"capital-loss\"]][AdultUCI[[ \"capital-loss\"]]>0]),Inf)),labels = c(\"none\", \"low\", \"high\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "head(AdultUCI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the data can be automatically recoded as a binary incidence matrix by coercing the data set to transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Adult <- as(AdultUCI, \"transactions\")\n",
    "Adult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 115 unique levels of data which form as columns and ofcourse 48842 transactions for the 48842 rows of original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inspect(Adult[1:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 115 categorical attributes were automatically recoded into 115 binary items. During encoding, the item labels were generated in the form of `<variable name>=<category label>`. Note that for cases with missing values all items corresponding to the attributes with the missing values were set to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary(Adult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary of the transaction data set gives a rough overview showing the most frequent items, the length distribution of the transactions and the extended item information which shows which variable and which value were used to create each binary item. \n",
    "\n",
    "In the first example we see that the item with label age=Middle-aged was generated by variable age and level middle-aged. age=Middle-aged is one of the 115 columns in the matrix. To see which items are important in the data set we can use the itemFrequencyPlot(). To reduce the number of items, we only plot the item frequency for items with a support greater than 30% (using the parameter support). For better readability of the labels, we reduce the label size with the parameter cex.names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itemFrequencyPlot(Adult, support = 0.3, cex.names=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interest Measures\n",
    "\n",
    "Many organizations generate a large amount of transaction data on a daily basis. For example, a department store like Macy’s stores customer shopping information at a large scale using check-out data. Association rule mining is one of the major techniques to detect and extract useful information from large scale transaction data.\n",
    "\n",
    "#### Support and Confidence\n",
    "\n",
    "Association rules are rules which surpass a user-specified minimum support and minimum confidence threshold. The support supp(X) of an itemset X is defined as the proportion of transactions in the data set which contain the itemset and the confidence of a rule is defined **_conf(X ⇒ Y )_** = **_supp(X ∪ Y )/supp(X)_**. Therefore, an association rule X ⇒ Y will satisfy below where where $\\sigma$ and δ are the minimum support and minimum confidence, respectively.\n",
    "\n",
    "$$ supp(X ∪ Y ) ≥ \\sigma $$\n",
    "\n",
    "                                                and\n",
    "\n",
    "$$ conf(X ⇒ Y ) ≥ δ $$\n",
    "\n",
    "\n",
    "\n",
    "#### lift \n",
    "\n",
    "Another popular measure for association rules is lift. The lift of a rule is defined as\n",
    "\n",
    "$$ lift(X ⇒ Y ) = \\frac{supp(X ∪ Y )}{(supp(X)supp(Y ))} $$\n",
    "\n",
    "Above formula can be interpreted as the deviation of the support of the whole rule from the support expected under independence given the supports of both sides of the rule. Greater lift values indicate stronger associations. Measures like support, confidence and lift are generally called interest measures because they help with focusing on potentially more interesting rules.\n",
    "\n",
    "Check the [reading material](../Resources/Basic_association_analysis.pdf) for detailed explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, call the function apriori() to find all ruleswith a minimum support of 1% and a confidence of 60%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rules <- apriori(Adult, parameter = list(support = 0.01, confidence = 0.6, maxlen=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the function prints the used parameters. Apart from the specified minimum support and minimum confidence, all parameters have the default values. It is important to note that with parameter maxlen, the maximum size of mined frequent itemsets, is by default restricted to 10. Longer association rules are only mined if maxlen is set to a higher value as we did set it to 20.\n",
    "\n",
    "\n",
    "The result of the mining algorithm is a set of 276709 rules. For an overview of the mined rules summary() can be used. It shows the number of rules, the most frequent items contained in the left-hand-side and the right-hand-side and their respective length distributions and summary statistics for the quality measures returned by the mining algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As typical for association rule mining, the number of rules found is huge. subset() can be used to produce separate subsets of rules for each item which resulted from the variable income in the right-hand-side of the rule and those with lift measure exceeding 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rulesIncomeSmall <- subset(rules, subset = rhs %in% \"income=small\" & lift > 1.2)\n",
    "rulesIncomeLarge <- subset(rules, subset = rhs %in% \"income=large\" & lift > 1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rulesIncomeSmall has a set with rules for persons with a small income and rulesIncomeLarge is a set for persons with large income. For comparison, inspect both sets for the three rules with the highest confidence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inspect(head(rulesIncomeSmall, n = 3, by = \"confidence\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inspect(head(rulesIncomeLarge, n = 3, by = \"confidence\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the rules we see that workers in the private sector working part-time or in the service industry tend to have a small income while persons with high capital gain who are born in the US tend to have a large income. This example shows that using subset selection and sorting a set of mined associations can be analyzed even if it is huge. \n",
    "\n",
    "Write the mined rules to disk. The following write() command saves set of rules as the file named ‘data.csv’ in comma separated value (CSV) format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write(rulesIncomeSmall, file = \"data.csv\", sep = \",\", col.names = NA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling\n",
    "\n",
    "\n",
    "Here we will see how sampling can be used in arules using the Adult data set again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Adult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an itemset _X_ with support τ = supp(X) and for an acceptable relative error of support $\\epsilon$ (an accuracy of 1 − $\\epsilon$) at a given confidence level c, the needed sample size **n** can be computed as shown below\n",
    "\n",
    "$$ n = \\frac{−2ln(c)}{ τ {\\epsilon}^2} $$\n",
    "\n",
    "For now, choose a minimum support of 5%. As an acceptable error rate for support $\\epsilon$ choose 10% and as the confidence level (1 − $\\epsilon$) choose 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "supp <- 0.05\n",
    "epsilon <- 0.1\n",
    "c <- 0.1\n",
    "n <- -2 * log(c)/ (supp * epsilon^2)\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting sample size is considerably smaller than the size of the original database. With sample(), a sample of size n with replacement from the database can be produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AdultSample <- sample(Adult, n, replace = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample can be compared with the database (the population) using an item frequency plot. The item frequencies in the sample are displayed as bars and the item frequencies in the original database are represented by the line. For better readability of the labels, only display frequent items in the plot and reduce the label size with the parameter cex.names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itemFrequencyPlot(AdultSample, population = Adult, support = supp, cex.names = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the speed-up reached by sampling we use the Eclat algorithm to mine frequent itemsets on both, the database and the sample and compare the system time (in seconds) used for mining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Eclat Reference: **](https://artax.karlin.mff.cuni.cz/r-help/library/arules/html/eclat.html)\n",
    "\n",
    "**Arguments**\n",
    "- data:  object of class transactions or any data structure which can be coerced into transactions (e.g., binary matrix, data.frame).\n",
    "- parameter: object of class ECparameter or named list (default values are: support 0.1 and maxlen 5)\n",
    "- control object of class ECcontrol or named list for algorithmic controls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time <- system.time(itemsets <- eclat(data = Adult, parameter = list(support = supp), control = list(verbose = FALSE)))\n",
    "time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paremeter verbose = FALSE will suppress all the summary deatils of running the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timeSample <- system.time(itemsetsSample <- eclat(AdultSample, parameter = list(support = supp), control = list(verbose = FALSE)))\n",
    "timeSample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first element of the vector returned by system.time() gives the (user) CPU time needed for the execution of the statement in its argument. Therefore, mining the sample instead of the whole data base results in a speed-up factor as calculated below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# speed up\n",
    "time[1] / timeSample[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the accuracy for the itemsets mined from the sample, analyze the difference between the two sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itemsetsSample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two sets have roughly the same size. To check if the sets contain similar itemsets, match the sets and see what fraction of frequent itemsets found in the database were also found in the sample\n",
    "\n",
    "**Reference: ** [match()](http://rfunction.com/archives/910)\n",
    "\n",
    "The match() function will look for elements of itemsets match those of itemsetsSample. Notice that only the first occurrence of each element of itemsets is reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match <- match(itemsets, itemsetsSample, nomatch = 0)\n",
    "match[1:10]\n",
    "\n",
    "# itemsets where there is no match 0 is assigned as mentioned in the parameter nomatch=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove no matches\n",
    "sum(match > 0) / length(itemsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all frequent itemsets were found using the sample. The summaries of the support of the frequent itemsets which were not found in the sample and the itemsets which were frequent in the sample although they were infrequent in the database, respectively, give"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary(quality(itemsets[match == 0])$support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary(quality(itemsetsSample[-match])$support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that only itemsets with support very close to the minimum support were falsely missed or found. For the frequent itemsets which were found in the database and in the sample, calculate accuracy from the the error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "supportItemsets <- quality(itemsets[which(match > 0)])$support\n",
    "supportSample <- quality(itemsetsSample[match])$support\n",
    "accuracy <- 1 - abs(supportSample - supportItemsets) / supportItemsets\n",
    "summary(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary shows that sampling resulted in finding the support of itemsets with high accuracy. This small example illustrates that for extremely large databases or for application where mining time is important, sampling can be a powerful technique"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
